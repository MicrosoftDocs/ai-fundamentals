{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics\n",
    "\n",
    "Natural Language Processing (NLP) is a branch of artificial intelligence (AI) that deals with written and spoken language. You can use NLP to build solutions that extracting semantic meaning from text or speech, or that formulate meaningful responses in natural language.\n",
    "\n",
    "Microsoft Azure *cognitive services* includes the *Text Analytics* service, which provides some out-of-the-box NLP capabilities, including the identification of key phrases in text, and the classification of text based on sentiment.\n",
    "\n",
    "<p style='text-align:center'><img src='./images/NLP.jpg' alt='A robot reading a notebook'/></p>\n",
    "\n",
    "For example, suppose the fictional *Margie's Travel* organization encourages customers to submit reviews for hotel stays. You could use the Text Analytics service to summarize the reviews by extracting key phrases, determine which reviews are positive and which are negative, or analyze the review text for mentions of known entities such as locations or people.\n",
    "\n",
    "## View Review Documents\n",
    "\n",
    "Let's start by taking a look at some hotel reviews that have been left by customers.\n",
    "\n",
    "The reviews are in text files. To see them, just run the cell below by clicking its green <span style=\"color:green\">&#9655</span> button (at the top left of the cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Read the reviews in the /data/reviews folder\n",
    "reviews_folder = os.path.join('data', 'text', 'reviews')\n",
    "\n",
    "# Create a collection of reviews with id (file name) and text (contents) properties\n",
    "reviews = []\n",
    "for file_name in os.listdir(reviews_folder):\n",
    "    review_text = open(os.path.join(reviews_folder, file_name)).read()\n",
    "    review = {\"id\": file_name, \"text\": review_text}\n",
    "    reviews.append(review)\n",
    "\n",
    "for review_num in range(len(reviews)):\n",
    "    # print the review text\n",
    "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Cognitive Services Resource\n",
    "\n",
    "To analyze the text in these reviews, you can use the **Text Analytics** cognitive service. To use this, you need to provision either a **Text Analytics** or **Cognitive Services** resource in your Azure subscription (Use a Text Analytics resource if this is the only service you plan to use or you want to track its usage separately; otherwise you can use a Cognitive Services resource to combine the Text Analytics service with other cognitive services - enabling developers to use a single endpoint and key to access them.)\n",
    "\n",
    "If you don't already have one, use the following steps to create a **Cognitive Services** resource in your Azure subscription:\n",
    "\n",
    "1. In another browser tab, open the Azure portal at https://portal.azure.com, signing in with your Microsoft account.\n",
    "2. Click the **&#65291;Create a resource** button, search for *Cognitive Services*, and create a **Cognitive Services** resource with the following settings:\n",
    "    - **Name**: *Enter a unique name*.\n",
    "    - **Subscription**: *Your Azure subscription*.\n",
    "    - **Location**: *Any available location*.\n",
    "    - **Pricing tier**: S0\n",
    "    - **Resource group**: *Create a resource group with a unique name*.\n",
    "3. Wait for deployment to complete. Then go to your cognitive services resource, and on the **Overview** page, click the link to manage the keys for the service. You will need the endpoint and keys to connect to your cognitive services resource from client applications.\n",
    "\n",
    "### Get the Key and Endpoint for your Cognitive Services resource\n",
    "\n",
    "To use your cognitive services resource, client applications need its  endpoint and authentication key:\n",
    "\n",
    "1. In the Azure portal, on the **Keys and Endpoint** page for your cognitive service resource, copy the **Key1** for your resource and paste it in the code below, replacing **YOUR_COG_KEY**.\n",
    "2. Copy the **endpoint** for your resource and and paste it in the code below, replacing **YOUR_COG_ENDPOINT**.\n",
    "3. Run the code in the cell below by clicking its green <span style=\"color:green\">&#9655</span> button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_key = 'YOUR_COG_KEY'\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Language\n",
    "Let's start by identifying the language in which these reviews are written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# Get a client for your text analytics cognitive service resource\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
    "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Analyze the reviews you read from the /data/reviews folder earlier\n",
    "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
    "\n",
    "# print detected language details for each review\n",
    "for review_num in range(len(reviews)):\n",
    "    # print the review id\n",
    "    print(reviews[review_num]['id'])\n",
    "\n",
    "    # Get the language details for this review\n",
    "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
    "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
    "\n",
    "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
    "    reviews[review_num][\"language\"] = lang.iso6391_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Key Phrases\n",
    "\n",
    "Now you can analyze the text in the customer reviews to identify key phrases that give some indication of the main talking points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the client and reviews you created in the previous code cell to get key phrases\n",
    "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
    "\n",
    "# print key phrases for each review\n",
    "for review_num in range(len(reviews)):\n",
    "    # print the review id\n",
    "    print(reviews[review_num]['id'])\n",
    "\n",
    "    # Get the key phrases in this review\n",
    "    print('\\nKey Phrases:')\n",
    "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
    "    # Print each key phrase\n",
    "    for key_phrase in key_phrases:\n",
    "        print('\\t', key_phrase)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key phrases can help you gain an understanding of the most important talking points in each review. For example, a review containing a phrase \"helpful staff\" or \"poor service\" can give you an indication of some of the main concerns of the reviewer.\n",
    "\n",
    "## Determine Sentiment\n",
    "\n",
    "It might be useful to classify the reviews as *positive* or *negative* based on a *sentiment score*. Again, you can use the Text Analytics service to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the client and reviews you created previously to get sentiment scores\n",
    "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
    "\n",
    "# Print the results for each review\n",
    "for review_num in range(len(reviews)):\n",
    "\n",
    "    # Get the sentiment score for this review\n",
    "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
    "\n",
    "    # classifiy 'positive' if more than 0.5, \n",
    "    if sentiment_score < 0.5:\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'positive'\n",
    "\n",
    "    # print file name and sentiment\n",
    "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Known Entities\n",
    "\n",
    "*Entities* are things that might be mentioned in text that reference some commonly understood type of item. For example, a location, a person, or a date. Let's suppose you're interested in dates and places mentioned in the reviews - you can use the following code to find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the client and reviews you created previously to get named entities\n",
    "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
    "\n",
    "# Print the results for each review\n",
    "for review_num in range(len(reviews)):\n",
    "    print(reviews[review_num]['id'])\n",
    "    # Get the named entitites in this review\n",
    "    entities = entity_analysis.documents[review_num].entities\n",
    "    for entity in entities:\n",
    "        # Only get location entitites\n",
    "        if entity.type in ['DateTime','Location']:\n",
    "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
    "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some entities are sufficiently well-known to have an associated Wikipedia page, in which case the Text Analytics service returns the URL for that page.\n",
    "\n",
    "## Learn More\n",
    "\n",
    "For more information about the Text Analytics service, see [the Text Analytics service documentation](https://docs.microsoft.com/azure/cognitive-services/text-analytics/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.5.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}