{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 顔の検出と分析\n",
    "\n",
    "コンピュータビジョンソリューションは、人間の顔を検出、分析、または識別するために人工知能（AI）ソリューションを必要とすることがよくあります。例えば、小売企業のノースウインド・トレーダーズが「スマートストア」の導入を決めたとします。これを実現するための1つの方法として、顔の検出と分析、つまり画像に顔が写っているかどうかを判断し、写っている場合はその特徴を分析することが挙げられます。\n",
    "\n",
    "\n",
    "<p style='text-align:center'><img src='./images/face_analysis.jpg' alt='顔を分析するロボット'/></p>\n",
    "\n",
    "\n",
    "## 顔認識サービスを使って顔を検出する\n",
    "\n",
    "Northwind Tradersが作りたいスマートストアシステムが、顧客を検知して顔の特徴を分析できる必要があるとします。Microsoft Azureでは、**Face**コグニティブサービスを使用してこれを行うことができます。\n",
    "\n",
    "まずはAzureサブスクリプションで**Cognitive Services**リソースを作成してみましょう。\n",
    "\n",
    "> **Note**: すでにCognitive Servicesリソースがある場合は、Azureポータルの**クイックスタート**ページを開き、そのキーとエンドポイントを以下のセルにコピーします。それ以外の場合は、以下の手順に従ってリソースを作成します。\n",
    "\n",
    "1. 別のブラウザタブで、https://portal.azure.com の Azure ポータルを開き、Microsoft アカウントでサインインします。\n",
    "\n",
    "2. **&#65291;Create a resource** ボタンをクリックして、*コグニティブサービス**を検索し、次の設定で**コグニティブサービス**リソースを作成します:\n",
    "    - **Name**: *一意の名前を入力してください*\n",
    "    - **Subscription**: *あなたのAzureサブスクリプション*\n",
    "    - **Location**: *利用可能なリージョンを選択:\n",
    "    - **Pricing tier**: S0\n",
    "    - **Resource group**: *固有の名前を持つリソースグループを作成します。*\n",
    "3. デプロイが完了するのを待ちます。次に、コグニティブサービスリソースに移動し、**クイックスタート**ページで、キーとエンドポイントに注意してください。クライアント アプリケーションからコグニティブ サービス リソースに接続するには、これらが必要です。\n",
    "\n",
    "4. リソースの **Key1** をコピーして、**YOUR_COG_KEY** を置き換えて、以下のコードに貼り付けます。\n",
    "5. リソースの **endpoint** をコピーして、以下のコードに貼り付け、 **YOUR_COG_ENDPOINT** を置き換えます。\n",
    "6. 下のセルの緑色の<span style=\"color:green\">&#9655;</span>ボタン（セルの左上）をクリックして、下のセルでコードを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_key = 'YOUR_COG_KEY'\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "source": [
    "これでCognitive Servicesのセットアップが完了しました。\n",
    "\n",
    "そしてPythonから本演習を実行するには、まずAzureの関連パッケージをインストールする必要があります。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-cognitiveservices-vision-face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで準備が完了しまして、Faceサービスを使って店内の人の顔を検出することができます。\n",
    "\n",
    "以下のコードセルを実行して例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from python_code import faces\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# 顔検出クライアントを作成します.\n",
    "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# 画像を開く\n",
    "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# 顔を検出\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# 顔を表示する (コードは python_code/faces.py にあります)\n",
    "faces.show_faces(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "検出された各顔には固有のIDが割り当てられているので、アプリケーションは検出された個々の顔を識別することができます。\n",
    "\n",
    "以下のセルを実行して、さらにいくつかの買い物客の顔のIDを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を開く\n",
    "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# 顔を検出\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# 顔を表示する (コードは python_code/faces.py にあります)\n",
    "faces.show_faces(image_path, detected_faces, show_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顔の属性を分析する\n",
    "\n",
    "Face cognitive サービスは、単に顔を検出するだけでなく、顔の特徴や表情を分析し、性別、年齢、感情状態を示唆することができます。また、顔の特徴や表情を分析して、性別、年齢、感情の状態を示唆することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を開く\n",
    "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# 顔と指定された顔の属性を検出します．\n",
    "attributes = ['age', 'gender', 'emotion']\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
    "\n",
    "# 顔と属性を表示する (コードは python_code/faces.py にあります)\n",
    "faces.show_face_attributes(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像に写っているお客様の感情スコアに基づいて、彼女は買い物に満足しているように見えます。\n",
    "\n",
    "## 似たような顔を探す\n",
    "\n",
    "検出された顔ごとに作成される顔ＩＤは、検出された顔を個別に識別するために使用されます。これらのIDを使用して、検出された顔を以前に検出された顔と比較したり、類似した特徴を持つ顔を見つけたりすることができます。\n",
    "\n",
    "例えば、以下のセルを実行して、ある画像の買い物客と別の画像の買い物客を比較し、一致する顔を見つけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像1の最初の顔のIDを取得します．\n",
    "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_1_stream = open(image_1_path, \"rb\")\n",
    "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
    "face_1 = image_1_faces[0]\n",
    "\n",
    "# 2枚目の画像で顔のIDを取得します\n",
    "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_2_stream = open(image_2_path, \"rb\")\n",
    "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
    "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
    "\n",
    "# 画像2から画像1の顔と似ている顔を探す\n",
    "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
    "\n",
    "# 画像1に顔を表示し，画像2に類似した顔を表示します(code in python_code/face.py)\n",
    "\n",
    "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顔を認識する\n",
    "\n",
    "ここまでで、Faceサービスが顔と顔の特徴を検出し、似たような2つの顔を識別できることを見てきました。顔認識*ソリューションを実装して、特定の人の顔を認識するようにFaceサービスのリソースを訓練することで、さらに一歩前進することができます。これは、ソーシャルメディアアプリケーションで友人の写真を自動的にタグ付けしたり、バイオメトリクス認証システムの一部として顔認証を使用したりするなど、さまざまなシナリオで役立ちます。\n",
    "\n",
    "これがどのように機能するかを確認するために、ノースウインド・トレーダーズ社が顔認証を使用して、IT部門の権限のある従業員だけが安全なシステムにアクセスできるようにしたいと考えているとします。\n",
    "\n",
    "権限を与えられた従業員を代表する*person group*を作成することから始めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = 'employee_group_id'\n",
    "try:\n",
    "    # 既に存在する場合はグループを削除します\n",
    "    face_client.person_group.delete(group_id)\n",
    "except Exception as ex:\n",
    "    print(ex.message)\n",
    "finally:\n",
    "    face_client.person_group.create(group_id, 'employees')\n",
    "    print ('Group created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで*personグループ*ができたので、グループに入れたい社員ごとに*person*を追加し、顔写真を複数枚登録して、フェイスサービスが顔の特徴を知ることができるようになります。理想的には、同じ人が異なるポーズや表情で写っているものが良いでしょう。\n",
    "\n",
    "ウェンデルという一人の社員を追加し、彼の写真を3枚登録します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# 人(Wendell)をグループに追加する\n",
    "wendell = face_client.person_group_person.create(group_id, 'Wendell')\n",
    "\n",
    "# Wendellの写真を手に入れる\n",
    "folder = os.path.join('data', 'face', 'wendell')\n",
    "wendell_pics = os.listdir(folder)\n",
    "\n",
    "# 写真を登録する\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for pic in wendell_pics:\n",
    "    # グループ内の人物に写真を追加する\n",
    "    img_path = os.path.join(folder, pic)\n",
    "    img_stream = open(img_path, \"rb\")\n",
    "    face_client.person_group_person.add_face_from_stream(group_id, wendell.person_id, img_stream)\n",
    "\n",
    "    #  各画像を表示する\n",
    "    img = Image.open(img_path)\n",
    "    i +=1\n",
    "    a=fig.add_subplot(1,len(wendell_pics), i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人物が追加され、写真が登録されたことで、一人一人を認識するためのFaceサービスのトレーニングができるようになりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_client.person_group.train(group_id)\n",
    "print('Trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでモデルが訓練されたので、画像中の認識された顔を識別するのに使用することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2枚目の画像で顔のIDを取得します\n",
    "image_path = os.path.join('data', 'face', 'employees.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "image_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "image_face_ids = list(map(lambda face: face.face_id, image_faces))\n",
    "\n",
    "# 認識された顔の名前を取得する\n",
    "face_names = {}\n",
    "recognized_faces = face_client.face.identify(image_face_ids, group_id)\n",
    "for face in recognized_faces:\n",
    "    person_name = face_client.person_group_person.get(group_id, face.candidates[0].person_id).name\n",
    "    face_names[face.face_id] = person_name\n",
    "\n",
    "# 認識した顔を表示\n",
    "faces.show_recognized_faces(image_path, image_faces, face_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn More\n",
    "\n",
    "Cognitive ServicesのFaceについては、[Faceドキュメント](https://docs.microsoft.com/azure/cognitive-services/face/)を参照してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}