{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 画像分類\n",
        "\n",
        "*Computer Vision*コグニティブサービスでは、画像を扱うための便利なモデルがあらかじめ用意されていますが、コンピュータビジョンのために独自のモデルをトレーニングする必要があることがよくあります。例えば、ノースウインド・トレーダーズの小売会社が、レジでカメラで撮影した画像に基づいて、顧客が購入したい食料品を識別する自動レジシステムを作成したいとします。そのためには、画像を分類して購入する商品を識別する分類モデルを訓練する必要があります。\n",
        "\n",
        "<p style='text-align:center'><img src='./images/image-classification.jpg' alt='A robot holding a clipboard, classifying pictures of an apple, a banana, and an orange'/></p>クリップボードを持ったロボットがリンゴ、バナナ、オレンジの画像を分類しています。\n",
        "\n",
        "Azureでは、**Custom Vision***コグニティブサービスを使用して、既存の画像に基づいて画像分類モデルをトレーニングすることができます。画像分類ソリューションを作成するには、2つの要素があります。まず、既存の画像を使用して異なるクラスを認識するモデルを訓練する必要があります。次に、モデルが訓練されたら、アプリケーションで利用できるサービスとして公開する必要があります。\n",
        "\n",
        "## カスタムビジョンリソースを作成する\n",
        "\n",
        "カスタムビジョンサービスを使用するには、モデルを*トレーニング*するために使用できるAzureリソースと、アプリケーションが使用するために*公開*できるリソースが必要です。どちらか（または両方）のタスクのリソースは、一般的な**Cognitive Services**リソースか、特定の**Custom Vision**リソースにすることができます。これらのタスクのそれぞれに同じコグニティブサービスリソースを使用することもできますし、コストを個別に管理するために、タスクごとに異なるリソース（同じリージョン内）を使用することもできます。\n",
        "\n",
        "以下の手順を使用して、新しい**Custom Vision**リソースを作成します。\n",
        "\n",
        "1. 新しいブラウザタブで、[https://portal.azure.com](https://portal.azure.com)のAzureポータルを開き、Azureサブスクリプションに関連付けられたMicrosoftアカウントを使用してサインインします。\n",
        "2. リソースの作成**ボタンを選択し、*カスタムビジョン**を検索し、以下の設定で**カスタムビジョン**リソースを作成します。:\n",
        "    - **Create options**: Both\n",
        "    - **Subscription**: *Your Azure subscription*\n",
        "    - **Resource group**: *Create a new resource group with a unique name*\n",
        "    - **Name**: *Enter a unique name*\n",
        "    - **Training location**: *Choose any available region*\n",
        "    - **Training pricing tier**: F0\n",
        "    - **Prediction location**: *The same region as the training resource*\n",
        "    - **Prediction pricing tier**: F0\n",
        "\n",
        "    > **注意**: すでにF0カスタムビジョンサービスを契約している場合は、**S0**を選択してください。\n",
        "    \n",
        "3. リソースが作成されるのを待ち、2 つのカスタムビジョンリソースがプロビジョニングされていることに注意してください。これらのリソースは、作成したリソースグループに移動して表示することができます。\n",
        "\n",
        "\n",
        "## Custom Visionプロジェクトを作成する\n",
        "\n",
        "オブジェクト検出モデルをトレーニングするには、トレーニングリソースに基づいてCustom Visionプロジェクトを作成する必要があります。これを行うには、Custom Vision ポータルを使用します。\n",
        "\n",
        "1. https://aka.ms/fruit-images からトレーニング画像をダウンロードして抽出します。\n",
        "2. 別のブラウザタブで、[https://customvision.ai](https://customvision.ai)のCustom Visionポータルを開きます。プロンプトが表示されたら、Azure サブスクリプションに関連付けられた Microsoft アカウントを使用してサインインし、利用規約に同意します。\n",
        "3. Custom Vision ポータルで、以下の設定で新しいプロジェクトを作成します。:\n",
        "    - **Name**: Grocery Checkout\n",
        "    - **Description**: Image classification for groceries\n",
        "    - **Resource**: *The Custom Vision resource you created previously*\n",
        "    - **Project Types**: Classification\n",
        "    - **Classification Types**: Multiclass (single tag per image)\n",
        "    - **Domains**: Food\n",
        "4. **\\[+\\] Add images**をクリックし、先ほど解凍した**apple**フォルダ内のファイルを全て選択します。そして、このように *apple* というタグを指定して画像ファイルをアップロードします。\n",
        "    <p style='text-align:center'><img src='/images/upload_apples.jpg' alt='Upload apple with apple tag'/></p>\n",
        "5. 前の手順を繰り返して、**banana**フォルダ内の画像を*banana*タグでアップロードし、**orange**フォルダ内の画像を*orange*タグでアップロードします。\n",
        "6. Custom Visionプロジェクトでアップロードした画像を見てみましょう。\n",
        "    <p style='text-align:center'><img src='./images/fruit.jpg' alt='果物のタグ付き画像 - リンゴ15個、バナナ15個、オレンジ15個'/></p>\n",
        "7. カスタムビジョンプロジェクトで、画像の上にある **トレーニング** をクリックして、タグ付けされた画像を使用して分類モデルをトレーニングします。**クイックトレーニング** オプションを選択し、トレーニングの反復が完了するのを待ちます（1分ほどかかる場合があります）。\n",
        "8. モデルの反復訓練が完了したら、*Precision*、*Recall*、および*AP*のパフォーマンスメトリクスを確認します - これらは、分類モデルの予測精度を測定するもので、すべてが高いはずです。\n",
        "\n",
        "## モデルをテストする\n",
        "\n",
        "Before publishing this iteration of the model for applications to use, you should test it.\n",
        "\n",
        "1. Above the performance metrics, click **Quick Test**.\n",
        "2. In the **Image URL** box, type `https://aka.ms/apple-image` and click &#10132;\n",
        "3. View the predictions returned by your model - the probability score for *apple* should be the highest, like this:\n",
        "    <p style='text-align:center'><img src='./images/test-apple.jpg' alt='An image with a class prediction of apple'/></p>\n",
        "4. Close the **Quick Test** window.\n",
        "\n",
        "## Publish and consume the image classification model\n",
        "\n",
        "Now you're ready to publish your trained model and use it from a client application.\n",
        "\n",
        "9. Click **&#128504; Publish** to publish the trained model with the following settings:\n",
        "    - **Model name**: groceries\n",
        "    - **Prediction Resource**: *The prediction resource you created previously*.\n",
        "10. After publishing, click the *settings* (&#9881;) icon at the top right of the **Performance** page to view the project settings. Then, under **General** (on the left), copy the **Project Id** and paste it into the code cell below (replacing **YOUR_PROJECT_ID**).\n",
        "    <p style='text-align:center'><img src='./images/cv_project_settings.jpg' alt='Project ID in project settings'/></p>\n",
        "\n",
        "> _**Note**: If you used a **Cognitive Services** resource instead of creating a **Custom Vision** resource at the beginning of this exercise, you can copy its key and endpoint from the right side of the project settings, paste it into the code cell below, and run it to see the results. Otherwise, continue completing the steps below to get the key and endpoint for your Custom Vision prediction resource._\n",
        "\n",
        "11. At the top left of the **Project Settings** page, click the *Projects Gallery* (&#128065;) icon to return to the Custom Vision portal home page, where your project is now listed.\n",
        "12. On the Custom Vision portal home page, at the top right, click the *settings* (&#9881;) icon to view the settings for your Custom Vision service. Then, under **Resources**, expand your *prediction* resource (<u>not</u> the training resource) and copy its **Key** and **Endpoint** values to the code cell below, replacing **YOUR_KEY** and **YOUR_ENDPOINT**.\n",
        "    <p style='text-align:center'><img src='./images/cv_settings.jpg' alt='Prediction resource key and endpoint in custom vision settings'/></p>\n",
        "13. Run the code cell below to set the variables to your project ID, key, and endpoint values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\n",
        "cv_key = 'YOUR_KEY'\n",
        "cv_endpoint = 'YOUR_ENDPOINT'\n",
        "\n",
        "model_name = 'groceries' # this must match the model name you set when publishing your model iteration (it's case-sensitive)!\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Client applications can use the details above to connect to and your custom vision classification model.\n",
        "\n",
        "Run the following code cell to classifiy a selection of test images using your published model.\n",
        "\n",
        "> **Note**: Don't worry too much about the details of the code. It uses the Computer Vision SDK for Python to get a class prediction for each image in the /data/image-classification/test-fruit folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Get the test images from the data/vision/test folder\n",
        "test_folder = os.path.join('data', 'image-classification', 'test-fruit')\n",
        "test_images = os.listdir(test_folder)\n",
        "\n",
        "# Create an instance of the prediction service\n",
        "custom_vision_client = CustomVisionPredictionClient(cv_key, endpoint=cv_endpoint)\n",
        "\n",
        "# Create a figure to display the results\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Get the images and show the predicted classes for each one\n",
        "print('Classifying images in {} ...'.format(test_folder))\n",
        "for i in range(len(test_images)):\n",
        "    # Open the image, and use the custom vision model to classify it\n",
        "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\n",
        "    # The results include a prediction for each tag, in descending order of probability - get the first one\n",
        "    prediction = classification.predictions[0].tag_name\n",
        "    # Display the image with its predicted class\n",
        "    img = Image.open(os.path.join(test_folder, test_images[i]))\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "    a.set_title(prediction)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hopefully, your image classification model has correctly identified the groceries in the images.\n",
        "\n",
        "## Learn more\n",
        "\n",
        "The Custom Vision service offers more capabilities than we've explored in this exercise. For example, you can also use the Custom Vision service to create *object detection* models; which not only classify objects in images, but also identify *bounding boxes* that show the location of the object in the image.\n",
        "\n",
        "To learn more about the Custom Vision cognitive service, view the [Custom Vision documentation](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.5.3-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}